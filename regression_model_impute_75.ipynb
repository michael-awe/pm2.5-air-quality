{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAGYkVjvz0AR"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQmKfTyM0eJh"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path('')\n",
    "\n",
    "# Load files\n",
    "train = pd.read_csv(DATA_PATH / 'Train.csv')\n",
    "test = pd.read_csv(DATA_PATH / 'Test.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH / 'SampleSubmission.csv')\n",
    "\n",
    "train.head()\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the The percentage of available data for each feature\n",
    "missing = (train.isnull().sum() / len(train)) * 100\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "\n",
    "#count number of missing features with 80%+\n",
    "missing_features = missing[missing > 75].count()\n",
    "print(f'There are {missing_features} features with more than 80% missing values')\n",
    "\n",
    "#plot column names with 80%+ missing\n",
    "# missing.plot.bar(figsize=(12, 6), color='blue', title='Percentage of missing values in the training data', ylabel='Percentage', xlabel='Features')\n",
    "\n",
    "#plot the missing values with a good graph with a title without the x labels\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "missing.plot.bar(ax=ax, color='blue', title='Percentage of missing values in the training data', ylabel='Percentage', xlabel='Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns less than 75% full\n",
    "train = train.dropna(thresh=0.25*len(train), axis=1)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows with 50% of missing values\n",
    "percentage_available = 0.75\n",
    "train = train.dropna(thresh=(percentage_available)*len(train.columns), axis=0)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine city and country into one column\n",
    "train['Location'] = train['country'] + ', ' + train['city']\n",
    "train.drop(['country', 'city', 'id'], axis=1, inplace=True)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the date column into day of the week, day of the month and year\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['day_of_month'] = train['date'].dt.day\n",
    "train['year'] = train['date'].dt.year\n",
    "train.drop('date', axis=1, inplace=True)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some feature engineering \n",
    "\n",
    "We'll use this to later describe the relationship between site_id and pm2.5 and why we decided to include it in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show pm2_5 distributions based on the site_id\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='site_id', y='pm2_5', data=train)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the Location and site_id columns\n",
    "train = pd.get_dummies(train, columns=['site_id'])\n",
    "train = pd.get_dummies(train, columns=['Location'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "columns = train.columns\n",
    "\n",
    "train = pd.DataFrame(imputer.fit_transform(train), columns=columns, index=train.index)\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Assume `df` is your DataFrame\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create the lineplot\n",
    "sns.lineplot(x='date', y='pm2_5', data=train)\n",
    "\n",
    "# Set the x-ticks to be every nth date, where n is the number of days between each tick\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # Set interval to your liking\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.title('Time series of pm2_5 by Location')\n",
    "plt.xticks(rotation=45)  # Rotate x-tick labels for better visibility\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Assume `df` is your DataFrame\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create the lineplot\n",
    "sns.lineplot(x='date', y='pm2_5', data=train, hue='Location')\n",
    "\n",
    "# Set the x-ticks to be every nth date, where n is the number of days between each tick\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # Set interval to your liking\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.title('Time series of pm2_5 by Location')\n",
    "plt.xticks(rotation=45)  # Rotate x-tick labels for better visibility\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the correlation of date and pm2_5 using a pretty time series graph, for each location\n",
    "plt.figure(figsize=(15, 8))\n",
    " \n",
    "sns.lineplot(x='month', y='pm2_5', data=train, hue='Location')\n",
    "plt.title('Time series of pm2_5 by Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the correlation of the hour and pm2_5 using a pretty time series graph, for each location\n",
    "plt.figure(figsize=(15, 8))\n",
    " \n",
    "sns.lineplot(x='hour', y='pm2_5', data=train, hue='Location')\n",
    "plt.title('Time series of pm2_5 by Location')\n",
    "plt.show()\n",
    "\n",
    "# Drop the hour column\n",
    "train = train.drop(columns=['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list non-categorical columns\n",
    "non_categorical = train.select_dtypes(include=[np.number]).columns\n",
    "# remove hour, month, latitude and longitude from this list\n",
    "non_categorical = non_categorical.drop(['hour', 'month', 'site_latitude', 'site_longitude', 'pm2_5'])\n",
    "non_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply transformation to pm2_5 level to reduce skewness\n",
    "\n",
    "#plot day of the week vs pm2_5\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x='day_of_week', y='pm2_5', data=train)\n",
    "plt.title('Day of the week vs pm2_5')\n",
    "plt.show()\n",
    "\n",
    "#plot day of the month vs pm2_5\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x='day_of_month', y='pm2_5', data=train)\n",
    "plt.title('Day of the month vs pm2_5')\n",
    "plt.show()\n",
    "\n",
    "#plot year vs pm2_5\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(x='year', y='pm2_5', data=train)\n",
    "plt.title('Year vs pm2_5')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are training the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "# scale the columns in the non-categorical columns list\n",
    "train[non_categorical] = scaler.fit_transform(train[non_categorical])\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = train.drop(columns=['pm2_5'])\n",
    "\n",
    "y = train['pm2_5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the model\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "\n",
    "# make some graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(y_train, label='Actual')\n",
    "sns.kdeplot(train_preds, label='Predictions')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "#add dropout layer\n",
    "\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer with single node for regression\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "# assess the model\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "\n",
    "# make some graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(y_train, label='Actual')\n",
    "sns.kdeplot(train_preds, label='Predictions')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate the model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "train_preds = rf.predict(X_train)\n",
    "test_preds = rf.predict(X_test)\n",
    "\n",
    "# Assess the model\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.str.replace('[^a-zA-Z0-9_]', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Local score\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print('Local RMSE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0s7m8Bvtz5UL",
    "outputId": "c9ec757a-e968-4662-d9ed-d174f20abf53"
   },
   "outputs": [],
   "source": [
    "\n",
    "# target distribution\n",
    "plt.figure(figsize = (11, 5))\n",
    "sns.histplot(train.pm2_5)\n",
    "plt.title('Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2pJ39tE2UGb"
   },
   "source": [
    "- From the target distribution histogram we can see that the distribution is skewed to the right.\n",
    "- Some processing of the target is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "LM0OERbEBTcY",
    "outputId": "4f960284-ec6f-419b-bd67-44494fcc3faf"
   },
   "outputs": [],
   "source": [
    "# Check for outliers in the target variable\n",
    "plt.figure(figsize = (11, 5))\n",
    "sns.boxplot(train.pm2_5)\n",
    "plt.title('Boxplot showing outliers - target variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1owzcQmQBsMF"
   },
   "source": [
    "- The target variable has some outliers that are beyond the 180 mark.\n",
    "- Outliers can be handled via\n",
    "  - Dropping them\n",
    "  - Cap outliers - set a maximum\n",
    "  - Assign a new value to the outliers\n",
    "  - Transform the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjyCfyTXsoq7"
   },
   "outputs": [],
   "source": [
    "# print a summary of each variable\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "id": "fAMgi5OMrbxg",
    "outputId": "f5842e59-7d13-4af1-d524-3176b557cf82"
   },
   "outputs": [],
   "source": [
    "# Select only numerical features\n",
    "train_num_df = train.select_dtypes(include=['number'])\n",
    "\n",
    "top10_corrs = abs(train_num_df.corr()['pm2_5']).sort_values(ascending = False).head(10)\n",
    "corr = train_num_df[list(top10_corrs.index)].corr()\n",
    "sns.heatmap(corr, cmap='RdYlGn', annot = True, center = 0)\n",
    "plt.title('Correlations between the target and other variables', pad = 15, fontdict={'size': 13})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
